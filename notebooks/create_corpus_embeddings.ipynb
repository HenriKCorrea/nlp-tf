{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961b6ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: transformers in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (4.53.1)\n",
      "Requirement already satisfied: huggingface_hub in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (0.33.2)\n",
      "Requirement already satisfied: omegaconf in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: datasets==2.16.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (2.16.1)\n",
      "Requirement already satisfied: filelock in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (2.3.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (20.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (0.7)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.16.1) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (3.12.13)\n",
      "Requirement already satisfied: packaging in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from datasets==2.16.1) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from huggingface_hub) (1.1.5)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from omegaconf) (4.9.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==2.16.1) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.16.1) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.16.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.16.1) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from pandas->datasets==2.16.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from pandas->datasets==2.16.1) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from pandas->datasets==2.16.1) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: nbconvert in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (7.16.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (5.8.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (5.10.4)\n",
      "Requirement already satisfied: packaging in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (25.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbconvert) (2.19.2)\n",
      "Requirement already satisfied: webencodings in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n",
      "Requirement already satisfied: decorator in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: stack_data in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jupyter-core>=4.7->nbconvert) (4.3.8)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbclient>=0.5.0->nbconvert) (8.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.5.1)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert) (4.24.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.26.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat>=5.7->nbconvert) (4.14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from beautifulsoup4->nbconvert) (2.7)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/developer/nlp-tf/.conda/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install python dependencies\n",
    "%pip install torch transformers huggingface_hub omegaconf datasets==2.16.1 \n",
    "# Optinal python packages for better user experience\n",
    "%pip install ipywidgets nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dca1d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import omegaconf\n",
    "import collections\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from collections import OrderedDict\n",
    "from transformers import DPRContextEncoder, AutoTokenizer, DPRConfig, GPT2TokenizerFast\n",
    "from huggingface_hub import hf_hub_download\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "# Setup external services authentication\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d1041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_keys_substring(ordered_dict: OrderedDict[str, Any], find_pattern, replace_pattern):\n",
    "    \"\"\"\n",
    "    Rename keys in an OrderedDict by replacing substring occurrences using regular expressions.\n",
    "    \n",
    "    Args:\n",
    "        ordered_dict: The OrderedDict to modify\n",
    "        find_pattern: The regex pattern to find in keys\n",
    "        replace_pattern: The replacement pattern (can include backreferences like \\\\1, \\\\2)\n",
    "    \n",
    "    Returns:\n",
    "        New Mapping with renamed keys\n",
    "    \"\"\"\n",
    "    new_dict = OrderedDict[str, Any]()\n",
    "    compiled_pattern = re.compile(find_pattern)\n",
    "    \n",
    "    for key, value in ordered_dict.items():\n",
    "        if not compiled_pattern.search(key):\n",
    "            continue\n",
    "            \n",
    "        new_key = compiled_pattern.sub(replace_pattern, key)\n",
    "        new_dict[new_key] = value\n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f585fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type dpr. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled for optimization\n"
     ]
    }
   ],
   "source": [
    "# Ensure that the necessary types are registered for safe deserialization\n",
    "torch.serialization.add_safe_globals(\n",
    "    [\n",
    "        omegaconf.dictconfig.ContainerMetadata,\n",
    "        omegaconf.dictconfig.DictConfig,\n",
    "        omegaconf.base.Metadata,\n",
    "        omegaconf.nodes.AnyNode,\n",
    "        omegaconf.listconfig.ListConfig,\n",
    "        collections.defaultdict,\n",
    "        Any,\n",
    "        dict,\n",
    "        list,\n",
    "        int,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Check if CUDA is available and set device accordingly\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model from checkpoint\n",
    "checkpoint_path = hf_hub_download(\n",
    "    repo_id=\"NTU-NLP-sg/xCodeEval-nl-code-starencoder-ckpt-37\",\n",
    "    filename=\"dpr_biencoder.37.pt\",\n",
    "    repo_type=\"model\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Retrieve fine-tuned weights\n",
    "# Pattern matches: question_model.embeddings/encoder.* -> question_encoder.bert_model.*\n",
    "ctx_state_dict = rename_keys_substring(\n",
    "    state_dict[\"model_dict\"],\n",
    "    r\"ctx_model\\.(embeddings|encoder)\\.([Ll]ayer|token|word|position_embeddings)\",\n",
    "    r\"ctx_encoder.bert_model.\\1.\\2\",\n",
    ")\n",
    "\n",
    "# Initialize encoders\n",
    "pretrained_model_name = state_dict[\"encoder_params\"][\"encoder\"][\"pretrained_model_cfg\"]\n",
    "encoder_config = DPRConfig.from_pretrained(\n",
    "    pretrained_model_name,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained(\n",
    "    None, state_dict=ctx_state_dict, config=encoder_config, token=HF_TOKEN\n",
    ")\n",
    "ctx_encoder = ctx_encoder.to(device).eval()\n",
    "\n",
    "# Compile for optimization (keeps same numerical results)\n",
    "if hasattr(torch, 'compile'):\n",
    "    ctx_encoder = torch.compile(ctx_encoder, mode='default')  # Use 'default' not 'max-autotune'\n",
    "    print(\"Model compiled for optimization\")\n",
    "\n",
    "# Distribute workload across multiple GPUs if available\n",
    "# Not so efficient as DistributedDataParallel, but simpler for single-node setups\n",
    "# DataParallel will split the input across the GPUs and gather the outputs\n",
    "# This is useful for inference or when the model is not too large\n",
    "if torch.cuda.device_count() > 1:\n",
    "    ctx_encoder = torch.nn.DataParallel(ctx_encoder)\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for context encoder\")\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer: GPT2TokenizerFast = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name, config=encoder_config\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fd19b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage():\n",
    "    \"\"\"Print current memory usage statistics\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()  # Ensure all GPU operations are complete\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / (1024**3)\n",
    "            reserved = torch.cuda.memory_reserved(i) / (1024**3)\n",
    "            total = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            print(f\"GPU {i}: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved, {total:.2f}GB total\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. No GPU memory stats to report.\")\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Comprehensive memory cleanup\"\"\"\n",
    "    # Clear Python garbage\n",
    "    gc.collect()\n",
    "    \n",
    "    # Clear PyTorch cache\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print memory stats\n",
    "    print_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81a1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_codes(batch: DatasetDict[str, list]):\n",
    "    inputs = tokenizer(\n",
    "        batch[\"source_code\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "        return_tensors=\"pt\"  # Use PyTorch tensors \n",
    "    )\n",
    "    # Move to device in one operation\n",
    "    inputs = {k: v.to(device, non_blocking=True) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad(), torch.amp.autocast(device_type=device, dtype=torch.bfloat16, enabled=True):\n",
    "        embeddings = ctx_encoder(**inputs).pooler_output\n",
    "        print_memory_usage()\n",
    "        # Convert to float16 to save memory if precision allows\n",
    "        embeddings_cpu = embeddings.detach().cpu().to(torch.float32).tolist()\n",
    "        return {\"embedding\": embeddings_cpu}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30cd9f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cache found. Processing corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61632e1853e24670956fc32a9f89b330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25043700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n",
      "GPU 0: 3.39GB allocated, 6.20GB reserved, 79.25GB total\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     23\u001b[39m corpus = load_dataset(\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNTU-NLP-sg/xCodeEval\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mretrieval_corpus\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     token=HF_TOKEN,\n\u001b[32m     30\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Generate embeddings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m corpus_with_embeddings = \u001b[43mcorpus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43membed_codes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m48\u001b[39;49m\n\u001b[32m     37\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEmbeddings generated successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaving corpus cache to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCORPUS_CACHE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp-tf/.conda/lib/python3.12/site-packages/datasets/arrow_dataset.py:592\u001b[39m, in \u001b[36mtransmit_tasks.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28mself\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    591\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    593\u001b[39m datasets: List[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[32m    595\u001b[39m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp-tf/.conda/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: List[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp-tf/.conda/lib/python3.12/site-packages/datasets/arrow_dataset.py:3093\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[39m\n\u001b[32m   3087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3088\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[32m   3089\u001b[39m         unit=\u001b[33m\"\u001b[39m\u001b[33m examples\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3090\u001b[39m         total=pbar_total,\n\u001b[32m   3091\u001b[39m         desc=desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3092\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m3093\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp-tf/.conda/lib/python3.12/site-packages/datasets/arrow_dataset.py:3470\u001b[39m, in \u001b[36mDataset._map_single\u001b[39m\u001b[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[39m\n\u001b[32m   3466\u001b[39m indices = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   3467\u001b[39m     \u001b[38;5;28mrange\u001b[39m(*(\u001b[38;5;28mslice\u001b[39m(i, i + batch_size).indices(shard.num_rows)))\n\u001b[32m   3468\u001b[39m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[32m   3469\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3470\u001b[39m     batch = \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3474\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3475\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3476\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[32m   3477\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[32m   3478\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3479\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp-tf/.conda/lib/python3.12/site-packages/datasets/arrow_dataset.py:3349\u001b[39m, in \u001b[36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[39m\u001b[34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[39m\n\u001b[32m   3347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[32m   3348\u001b[39m     additional_args += (rank,)\n\u001b[32m-> \u001b[39m\u001b[32m3349\u001b[39m processed_inputs = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[32m   3351\u001b[39m     processed_inputs = {\n\u001b[32m   3352\u001b[39m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs.data.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs.keys_to_format\n\u001b[32m   3353\u001b[39m     }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36membed_codes\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(), torch.amp.autocast(device_type=device, dtype=torch.bfloat16, enabled=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     13\u001b[39m     embeddings = ctx_encoder(**inputs).pooler_output\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mprint_memory_usage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Convert to float16 to save memory if precision allows\u001b[39;00m\n\u001b[32m     16\u001b[39m     embeddings_cpu = embeddings.detach().cpu().to(torch.float32).tolist()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mprint_memory_usage\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Print current memory usage statistics\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure all GPU operations are complete\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(torch.cuda.device_count()):\n\u001b[32m      6\u001b[39m         allocated = torch.cuda.memory_allocated(i) / (\u001b[32m1024\u001b[39m**\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nlp-tf/.conda/lib/python3.12/site-packages/torch/cuda/__init__.py:1040\u001b[39m, in \u001b[36msynchronize\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m   1038\u001b[39m _lazy_init()\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.device(device):\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Configure cache settings\n",
    "CACHE_DIR = Path(\"./cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "CORPUS_CACHE_DIR = CACHE_DIR / \"corpus_embeddings\"\n",
    "\n",
    "# Check if cache exists and load, otherwise process corpus\n",
    "if CORPUS_CACHE_DIR.exists():\n",
    "    try:\n",
    "        print(f\"Loading corpus cache from {CORPUS_CACHE_DIR}\")\n",
    "        corpus_with_embeddings = Dataset.load_from_disk(str(CORPUS_CACHE_DIR))\n",
    "        print(f\"Cache loaded successfully. Documents: {len(corpus_with_embeddings)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load cache: {e}\")\n",
    "        print(\"Cache directory exists but contains invalid data. Recreating cache...\")\n",
    "        corpus_with_embeddings = None\n",
    "else:\n",
    "    corpus_with_embeddings = None\n",
    "\n",
    "if corpus_with_embeddings is None:\n",
    "    print(\"No cache found. Processing corpus...\")\n",
    "    \n",
    "    # Load corpus dataset\n",
    "    corpus = load_dataset(\n",
    "        \"NTU-NLP-sg/xCodeEval\",\n",
    "        \"retrieval_corpus\",\n",
    "        trust_remote_code=True,\n",
    "        split=\"test\",\n",
    "        revision=\"467d25a839086383794b58055981221b82c0d107\",\n",
    "        token=HF_TOKEN,\n",
    "    )\n",
    "    \n",
    "    # Generate embeddings\n",
    "    corpus_with_embeddings = corpus.map(\n",
    "        embed_codes,\n",
    "        batched=True,\n",
    "        batch_size=48\n",
    "    )\n",
    "    \n",
    "    print(\"Embeddings generated successfully!\")\n",
    "    print(f\"Saving corpus cache to {CORPUS_CACHE_DIR}\")\n",
    "    corpus_with_embeddings.save_to_disk(str(CORPUS_CACHE_DIR))\n",
    "    print(\"Cache saved successfully!\")\n",
    "\n",
    "# Display information about the processed corpus\n",
    "print(f\"\\nCorpus information:\")\n",
    "print(f\"Number of documents: {len(corpus_with_embeddings)}\")\n",
    "if len(corpus_with_embeddings) > 0:\n",
    "    print(f\"Embedding dimension: {len(corpus_with_embeddings[0]['embedding'])}\")\n",
    "    print(f\"Sample document keys: {list(corpus_with_embeddings[0].keys())}\")\n",
    "    print(f\"Sample source code (first 200 chars): {corpus_with_embeddings[0]['source_code'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9dba0",
   "metadata": {},
   "source": [
    "Allocated GPU: 6.60GB\n",
    "400 docs/s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
